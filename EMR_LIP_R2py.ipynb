{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union, Optional, Any, Callable\n",
    "from EMR_LIP_py import get_dtype_dict\n",
    "\n",
    "class EMR_LIP:\n",
    "    def __init__(self, var_dict: pd.DataFrame, table_type: str = \"long\"):\n",
    "        \"\"\"Initialize EMR_LIP class.\n",
    "        \n",
    "        Args:\n",
    "            var_dict: DataFrame containing variable definitions\n",
    "            table_type: Type of table format ('long' or 'wide')\n",
    "        \"\"\"\n",
    "        self.var_dict = var_dict.copy()\n",
    "        self.table_type = table_type\n",
    "        self._validate_inputs()\n",
    "        self.stats = {}\n",
    "        \n",
    "        # 定义聚合函数字典\n",
    "        self.AGG_FUNCS = {\n",
    "            'mean': self._mean,\n",
    "            'median': self._median,\n",
    "            'mode': self._mode,\n",
    "            'mode_w': self._mode_w,\n",
    "            'mean_w': self._mean_w,\n",
    "            'median_w': self._median_w,\n",
    "            'min': self._min,\n",
    "            'max': self._max,\n",
    "            'first': self._get_first,\n",
    "            'last': self._get_last,\n",
    "            'any': self._any,\n",
    "            'all': self._all,\n",
    "            'sum': np.sum,\n",
    "            'sum_w': np.sum\n",
    "        }\n",
    "\n",
    "    def _get_type(self, itemid: str) -> str:\n",
    "        \"\"\"Get variable type.\"\"\"\n",
    "        return self.var_dict.loc[self.var_dict['itemid'] == itemid, 'value_type'].iloc[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean(x: pd.Series, na_rm: bool = True) -> float:\n",
    "        \"\"\"Calculate mean.\n",
    "        \n",
    "        Args:\n",
    "            x: Input series\n",
    "            na_rm: Whether to remove NA values\n",
    "            \n",
    "        Returns:\n",
    "            Mean value as float or None if series is empty\n",
    "        \"\"\"\n",
    "        # 直接使用pandas的mean方法，它内置了NA处理\n",
    "        result = x.mean() if na_rm else x.mean(skipna=False)\n",
    "        return float(result) if pd.notna(result) else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _median(x: pd.Series, na_rm: bool = True) -> float:\n",
    "        \"\"\"Calculate median.\n",
    "        \n",
    "        Args:\n",
    "            x: Input series\n",
    "            na_rm: Whether to remove NA values\n",
    "            \n",
    "        Returns:\n",
    "            Median value as float or None if series is empty\n",
    "        \"\"\"\n",
    "        # 直接使用pandas的median方法，它内置了NA处理\n",
    "        result = x.median() if na_rm else x.median(skipna=False)\n",
    "        return float(result) if pd.notna(result) else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _mode(x: pd.Series, na_rm: bool = True) -> str:\n",
    "        \"\"\"Calculate mode.\"\"\"\n",
    "        if na_rm:\n",
    "            x = x.dropna()\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        \n",
    "        # 获取值计数\n",
    "        value_counts = x.value_counts()\n",
    "        if len(value_counts) == 0:\n",
    "            return None\n",
    "            \n",
    "        # 获取最大频率\n",
    "        max_freq = value_counts.iloc[0]\n",
    "        # 获取所有具有最大频率的值\n",
    "        modes = value_counts[value_counts == max_freq].index.tolist()\n",
    "        \n",
    "        if len(modes) == 0:\n",
    "            return None\n",
    "        elif len(modes) == 1:\n",
    "            return str(modes[0])\n",
    "        else:\n",
    "            return str(x[x.isin(modes)][::-1].iloc[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def _mode_w(x: pd.Series, weights: pd.Series, na_rm: bool = True) -> str:\n",
    "        \"\"\"Calculate weighted mode.\"\"\"\n",
    "        if na_rm:\n",
    "            mask = x.notna()\n",
    "            x = x[mask]\n",
    "            weights = weights[mask]\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        # 计算加权频率\n",
    "        weighted_counts = pd.Series(weights.values, index=x).groupby(level=0).sum()\n",
    "        return str(weighted_counts.idxmax())\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean_w(x: pd.Series, weights: pd.Series, na_rm: bool = True) -> float:\n",
    "        \"\"\"Calculate weighted mean.\"\"\"\n",
    "        if na_rm:\n",
    "            mask = x.notna()\n",
    "            x = x[mask]\n",
    "            weights = weights[mask]\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        return float(np.average(x, weights=weights))\n",
    "\n",
    "    @staticmethod\n",
    "    def _median_w(x: pd.Series, weights: pd.Series, na_rm: bool = True) -> float:\n",
    "        \"\"\"Calculate weighted median.\"\"\"\n",
    "        if na_rm:\n",
    "            mask = x.notna()\n",
    "            x = x[mask]\n",
    "            weights = weights[mask]\n",
    "        if len(x) == 0:\n",
    "            return None\n",
    "        # 计算加权中位数\n",
    "        sorted_idx = np.argsort(x)\n",
    "        sorted_weights = weights.iloc[sorted_idx]\n",
    "        cumsum = np.cumsum(sorted_weights)\n",
    "        median_loc = np.searchsorted(cumsum, cumsum[-1] / 2)\n",
    "        return float(x.iloc[sorted_idx[median_loc]])\n",
    "\n",
    "    @staticmethod\n",
    "    def _min(x: pd.Series, na_rm: bool = True) -> float:\n",
    "        \"\"\"Calculate minimum.\"\"\"\n",
    "        if na_rm:\n",
    "            x = x.dropna()\n",
    "        return float(np.min(x)) if len(x) > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _max(x: pd.Series, na_rm: bool = True) -> float:\n",
    "        \"\"\"Calculate maximum.\"\"\"\n",
    "        if na_rm:\n",
    "            x = x.dropna()\n",
    "        return float(np.max(x)) if len(x) > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_first(x: pd.Series, na_rm: bool = True) -> Any:\n",
    "        \"\"\"Get first value.\"\"\"\n",
    "        if na_rm:\n",
    "            x = x.dropna()\n",
    "        return x.iloc[0] if len(x) > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_last(x: pd.Series, na_rm: bool = True) -> Any:\n",
    "        \"\"\"Get last value.\"\"\"\n",
    "        if na_rm:\n",
    "            x = x.dropna()\n",
    "        return x.iloc[-1] if len(x) > 0 else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _any(x: pd.Series, na_rm: bool = True) -> int:\n",
    "        \"\"\"Calculate any.\n",
    "        \n",
    "        Args:\n",
    "            x: Input series\n",
    "            na_rm: Whether to remove NA values\n",
    "            \n",
    "        Returns:\n",
    "            1 if any value is True, 0 if all values are False, None if series is empty\n",
    "        \"\"\"\n",
    "        # 直接使用pandas的any方法，它内置了NA处理\n",
    "        result = x.any() if na_rm else x.any(skipna=False)\n",
    "        return int(result) if pd.notna(result) else None\n",
    "\n",
    "    @staticmethod\n",
    "    def _all(x: pd.Series, na_rm: bool = True) -> int:\n",
    "        \"\"\"Calculate all.\n",
    "        \n",
    "        Args:\n",
    "            x: Input series\n",
    "            na_rm: Whether to remove NA values\n",
    "            \n",
    "        Returns:\n",
    "            1 if all values are True, 0 if any value is False, None if series is empty\n",
    "        \"\"\"\n",
    "        # 直接使用pandas的all方法，它内置了NA处理\n",
    "        result = x.all() if na_rm else x.all(skipna=False)\n",
    "        return int(result) if pd.notna(result) else None\n",
    "\n",
    "    def _validate_inputs(self):\n",
    "        \"\"\"Validate input parameters.\"\"\"\n",
    "        if not isinstance(self.var_dict, pd.DataFrame):\n",
    "            raise TypeError(\"var_dict must be a pandas DataFrame\")\n",
    "        if self.table_type not in [\"wide\", \"long\"]:\n",
    "            raise ValueError(\"table_type must be either 'wide' or 'long'\")\n",
    "\n",
    "    ##############################\n",
    "    # Table Renaming\n",
    "    ##############################\n",
    "    def rename_table(self, data: pd.DataFrame, old_name_list: List[str], new_name_list: List[str], \n",
    "                    name_col: Optional[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"Rename variables in wide or long table.\n",
    "        \n",
    "        Args:\n",
    "            data: Input DataFrame\n",
    "            old_name_list: List of old variable names\n",
    "            new_name_list: List of new variable names\n",
    "            name_col: Column name containing variable names (for long format)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with renamed variables\n",
    "        \"\"\"\n",
    "        if len(old_name_list) != len(new_name_list):\n",
    "            raise ValueError(\"old_name_list and new_name_list must have the same length\")\n",
    "        \n",
    "        result = data.copy()    \n",
    "        if self.table_type == \"wide\":\n",
    "            result.rename(columns=dict(zip(old_name_list, new_name_list)), inplace=True)\n",
    "        elif self.table_type == \"long\" and name_col:\n",
    "            result[name_col] = result[name_col].replace(dict(zip(old_name_list, new_name_list)))\n",
    "        \n",
    "        return result\n",
    "\n",
    "    ##############################\n",
    "    # Remove Extreme Values\n",
    "    ##############################\n",
    "    def remove_extreme_values(self, data: pd.DataFrame, \n",
    "                              itemid_list: List[str], \n",
    "                              type_list: List[str],\n",
    "                              itemid_col: str = None, \n",
    "                              value_col: str = None,\n",
    "                              sep: str = \"___\") -> pd.DataFrame:\n",
    "        \"\"\"Remove extreme values from variables based on their types.\n",
    "        \n",
    "        Args:\n",
    "            data: Input DataFrame\n",
    "            itemid_list: List of item IDs\n",
    "            type_list: List of variable types\n",
    "            itemid_col: Column name for item IDs (for long format)\n",
    "            value_col: Column name for values (for long format)\n",
    "            sep: Separator for splitting valid values string\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with extreme values removed\n",
    "        \"\"\"\n",
    "        result = data.copy()\n",
    "        \n",
    "        if self.table_type == \"wide\":\n",
    "            for i, (col, var_type) in enumerate(zip(itemid_list, type_list)):\n",
    "                if var_type == \"num\":\n",
    "                    # 处理数值型变量\n",
    "                    low = self.var_dict.loc[i, \"low\"]\n",
    "                    high = self.var_dict.loc[i, \"high\"]\n",
    "                    if pd.notna(low):\n",
    "                        result[col] = result[col].where(result[col] >= low, np.nan)\n",
    "                    if pd.notna(high):\n",
    "                        result[col] = result[col].where(result[col] <= high, np.nan)\n",
    "                        \n",
    "                elif var_type in [\"ord\", \"cat\"]:\n",
    "                    # 处理有序型和分类型变量\n",
    "                    valid_values = self.var_dict.loc[i, \"valid_value\"]\n",
    "                    if pd.notna(valid_values):\n",
    "                        # 首先用sep分割，然后用'|'进一步分割\n",
    "                        valid_list = [v.strip() for v in valid_values.split('|')]\n",
    "                        result[col] = result[col].where(result[col].isin(valid_list), np.nan)\n",
    "                        \n",
    "                # bin类型不需要处理\n",
    "                \n",
    "        else:  # long format\n",
    "            for i, (itemid, var_type) in enumerate(zip(itemid_list, type_list)):\n",
    "                ind = (result[itemid_col] == itemid)\n",
    "                \n",
    "                if var_type == \"num\":\n",
    "                    # 处理数值型变量\n",
    "                    low = self.var_dict.loc[i, \"low\"]\n",
    "                    high = self.var_dict.loc[i, \"high\"]\n",
    "                    values = pd.to_numeric(result.loc[ind, value_col], errors='coerce')\n",
    "                    \n",
    "                    if pd.notna(low):\n",
    "                        values = values.where(values >= low, np.nan)\n",
    "                    if pd.notna(high):\n",
    "                        values = values.where(values <= high, np.nan)\n",
    "                        \n",
    "                    result.loc[ind, value_col] = values\n",
    "                    \n",
    "                elif var_type in [\"ord\", \"cat\"]:\n",
    "                    # 处理有序型和分类型变量\n",
    "                    valid_values = self.var_dict.loc[i, \"valid_value\"]\n",
    "                    if pd.notna(valid_values):\n",
    "                        # 首先用sep分割，然后用'|'进一步分割\n",
    "                        valid_list = [v.strip() for v in valid_values.split('|')]\n",
    "                        values = result.loc[ind, value_col].astype(str)\n",
    "                        result.loc[ind, value_col] = values.where(values.isin(valid_list), np.nan)\n",
    "                        \n",
    "                # bin类型不需要处理\n",
    "                \n",
    "        return result\n",
    "\n",
    "    ##############################\n",
    "    # Calculate Statistics\n",
    "    ##############################\n",
    "\n",
    "    def calculate_stats(self, data: pd.DataFrame, itemid_list: List[str], type_list: List[str], \n",
    "                    itemid_col: str = None, value_col: str = None,\n",
    "                    cont_list: List = None, sep: str = \"___\") -> Dict:\n",
    "        \"\"\"Calculate statistics for variables.\"\"\"\n",
    "        self.stats = {}\n",
    "        \n",
    "        for i, (itemid, var_type) in enumerate(zip(itemid_list, type_list)):\n",
    "            # Get values based on table type\n",
    "            if self.table_type == \"wide\":\n",
    "                values = data[itemid]\n",
    "            else:\n",
    "                mask = data[itemid_col] == itemid\n",
    "                values = data.loc[mask, value_col]\n",
    "            \n",
    "            # Get continuation value\n",
    "            cont = cont_list[i] if cont_list is not None else None\n",
    "            \n",
    "            # Calculate statistics based on variable type\n",
    "            if var_type == \"num\":\n",
    "                numeric_values = pd.to_numeric(values, errors='coerce')\n",
    "                stats = {\n",
    "                    \"type\": var_type,\n",
    "                    \"mean\": self._mean(numeric_values),  # 用于 fill_missing\n",
    "                    \"cont\": cont if pd.notna(cont) else self._mean(numeric_values)  # 用于 fill_missing\n",
    "                }\n",
    "            \n",
    "            elif var_type in [\"cat\", \"ord\"]:  # 合并处理 cat 和 ord\n",
    "                mode_val = self._mode(values)  # 用于 fill_missing\n",
    "                # 从 var_dict 获取 valid_value\n",
    "                valid_value = self.var_dict.loc[self.var_dict['itemid'] == itemid, 'valid_value'].iloc[0]\n",
    "                if pd.notna(valid_value):\n",
    "                    # 使用'|'分割并去除空白字符\n",
    "                    unique_vals = sorted(v.strip() for v in valid_value.split('|'))\n",
    "                else:\n",
    "                    unique_vals = sorted(values.dropna().unique())  # 如果 valid_value 为空则使用数据中的唯一值\n",
    "                stats = {\n",
    "                    \"type\": var_type,\n",
    "                    \"mode\": mode_val,\n",
    "                    \"unique_values\": unique_vals,\n",
    "                    \"cont\": cont if pd.notna(cont) else mode_val\n",
    "                }\n",
    "            \n",
    "            elif var_type == \"bin\":\n",
    "                numeric_values = pd.to_numeric(values, errors='coerce')\n",
    "                stats = {\n",
    "                    \"type\": var_type,\n",
    "                    \"mean\": self._mean(numeric_values),  # 用于 fill_missing\n",
    "                    \"cont\": cont if pd.notna(cont) else 0  # 用于 fill_missing\n",
    "                }\n",
    "            \n",
    "            self.stats[itemid] = stats\n",
    "\n",
    "        return\n",
    "\n",
    "    ##############################\n",
    "    # Resample Data\n",
    "    ##############################\n",
    "    def resample(self, ds: pd.DataFrame,\n",
    "                time_list: List[str], \n",
    "                itemid_list: List[str] = None,\n",
    "                type_list: List[str] = None,\n",
    "                agg_funcs: Dict[str, Callable] = None,\n",
    "                time_col: str = 'time',\n",
    "                value_col: str = 'value',\n",
    "                itemid_col: str = 'itemid',\n",
    "                time_window: str = '1H',\n",
    "                direction: str = 'forward',\n",
    "                start_col: str = None,\n",
    "                end_col: str = None,\n",
    "                keep_na_row: bool = True,\n",
    "                keep_first: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Resample data based on time windows and table type.\n",
    "        \n",
    "        Args:\n",
    "            ds: Input DataFrame\n",
    "            time_list: List of time points to sample at\n",
    "            itemid_list: List of item IDs\n",
    "            type_list: List of variable types\n",
    "            agg_funcs: List of aggregation functions\n",
    "            time_col: Name of time column\n",
    "            value_col: Name of value column (for long format)\n",
    "            itemid_col: Name of item ID column (for long format)\n",
    "            time_window: Size of time window\n",
    "            direction: Direction of time window ('both', 'left', or 'right')\n",
    "            start_col: Name of start time column (optional)\n",
    "            end_col: Name of end time column (optional)\n",
    "            keep_na_row: Whether to keep rows with all NA values\n",
    "            keep_first: Whether to keep first row if all NA\n",
    "            \n",
    "        Returns:\n",
    "            Resampled DataFrame\n",
    "        \"\"\"\n",
    "        # 根据表格类型选择不同的重采样方法\n",
    "        if self.table_type == \"wide\":\n",
    "            result = self._resample_wide(\n",
    "                ds=ds,\n",
    "                time_list=time_list,\n",
    "                itemid_list=itemid_list,\n",
    "                type_list=type_list,\n",
    "                agg_funcs=agg_funcs,\n",
    "                time_col=time_col,\n",
    "                end_col=end_col,\n",
    "                time_window=time_window,\n",
    "                direction=direction,\n",
    "                keep_na_row=keep_na_row,\n",
    "                keep_first=keep_first\n",
    "            )\n",
    "        else:\n",
    "            result = self._resample_long(\n",
    "                ds=ds,\n",
    "                time_list=time_list,\n",
    "                itemid_list=itemid_list,\n",
    "                type_list=type_list,\n",
    "                agg_funcs=agg_funcs,\n",
    "                itemid_col=itemid_col,\n",
    "                value_col=value_col,\n",
    "                time_col=time_col,\n",
    "                end_col=end_col,\n",
    "                time_window=time_window,\n",
    "                direction=direction,\n",
    "                keep_na_row=keep_na_row,\n",
    "                keep_first=keep_first\n",
    "            )\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _resample_wide(self, ds: pd.DataFrame, time_list: List[int], \n",
    "                    itemid_list: List[str], type_list: List[str], \n",
    "                    agg_funcs: List[Union[str, Callable]], time_col: str, \n",
    "                    end_col: str = None, time_window: int = 1, \n",
    "                    direction: str = \"both\", keep_na_row: bool = False, \n",
    "                    keep_first: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Resample wide format data.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for cur_t in time_list:\n",
    "            # 根据是否有区间数据确定时间过滤条件\n",
    "            if end_col is None:\n",
    "                # 点数据的时间过滤\n",
    "                if direction == \"both\":\n",
    "                    time_mask = (ds[time_col] >= (cur_t - time_window/2)) & \\\n",
    "                            (ds[time_col] <= (cur_t + time_window/2))\n",
    "                elif direction == \"left\":\n",
    "                    time_mask = (ds[time_col] >= (cur_t - time_window)) & \\\n",
    "                            (ds[time_col] <= cur_t)\n",
    "                elif direction == \"right\":\n",
    "                    time_mask = (ds[time_col] >= cur_t) & \\\n",
    "                            (ds[time_col] <= (cur_t + time_window))\n",
    "            else:\n",
    "                # 区间数据的时间过滤\n",
    "                if direction == \"both\":\n",
    "                    time_mask = ((ds[end_col].isna() & \n",
    "                                (ds[time_col] >= (cur_t - time_window/2)) & \n",
    "                                (ds[time_col] <= (cur_t + time_window/2))) |\n",
    "                            (~ds[end_col].isna() & \n",
    "                                (ds[time_col] <= (cur_t + time_window/2)) & \n",
    "                                (ds[end_col] >= (cur_t - time_window/2))))\n",
    "                elif direction == \"left\":\n",
    "                    time_mask = ((ds[end_col].isna() & \n",
    "                                (ds[time_col] >= (cur_t - time_window)) & \n",
    "                                (ds[time_col] <= cur_t)) |\n",
    "                            (~ds[end_col].isna() & \n",
    "                                (ds[time_col] <= cur_t) & \n",
    "                                (ds[end_col] >= (cur_t - time_window))))\n",
    "                elif direction == \"right\":\n",
    "                    time_mask = ((ds[end_col].isna() & \n",
    "                                (ds[time_col] >= cur_t) & \n",
    "                                (ds[time_col] <= (cur_t + time_window))) |\n",
    "                            (~ds[end_col].isna() & \n",
    "                                (ds[time_col] <= (cur_t + time_window)) & \n",
    "                                (ds[end_col] >= cur_t)))\n",
    "            \n",
    "            ds_cur = ds[time_mask].copy()\n",
    "            \n",
    "            if len(ds_cur) == 0:\n",
    "                results.append([\"0\"] + [None] * len(itemid_list))\n",
    "                continue\n",
    "                \n",
    "            # 计算重叠部分（仅对区间数据）\n",
    "            if end_col is not None:\n",
    "                if direction == \"both\":\n",
    "                    overlap = np.minimum(ds_cur[end_col], cur_t + time_window/2) - \\\n",
    "                            np.maximum(ds_cur[time_col], cur_t - time_window/2)\n",
    "                elif direction == \"left\":\n",
    "                    overlap = np.minimum(ds_cur[end_col], cur_t) - \\\n",
    "                            np.maximum(ds_cur[time_col], cur_t - time_window)\n",
    "                elif direction == \"right\":\n",
    "                    overlap = np.minimum(ds_cur[end_col], cur_t + time_window) - \\\n",
    "                            np.maximum(ds_cur[time_col], cur_t)\n",
    "                \n",
    "                overlap = np.maximum(overlap, 0)\n",
    "                total = ds_cur[end_col] - ds_cur[time_col]\n",
    "                ds_cur['proportion'] = overlap / total\n",
    "            \n",
    "            # 对每个变量应用聚合函数\n",
    "            cur_x = []\n",
    "            for itemid, var_type, agg_f in zip(itemid_list, type_list, agg_funcs):\n",
    "                x = ds_cur[itemid]\n",
    "                \n",
    "                if var_type == \"num\":\n",
    "                    x = pd.to_numeric(x, errors='coerce')\n",
    "                    if end_col is not None and agg_f in ['mean_w', 'median_w']:\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x, overlap)\n",
    "                    elif end_col is not None and agg_f == 'sum_w':\n",
    "                        x = x * ds_cur['proportion']\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                    else:\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                elif var_type in [\"cat\", \"ord\"]:\n",
    "                    x = x.astype(str)\n",
    "                    if end_col is not None and agg_f == 'mode_w':\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x, overlap)\n",
    "                    else:\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                elif var_type == \"bin\":\n",
    "                    x = pd.to_numeric(x, errors='coerce')\n",
    "                    agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                \n",
    "                cur_x.append(agg_value)\n",
    "            \n",
    "            results.append([\"1\"] + cur_x)\n",
    "        \n",
    "        # 转换为DataFrame\n",
    "        result = pd.DataFrame(results, columns=[\"keep\"] + itemid_list)\n",
    "        result.insert(0, \"time\", time_list)\n",
    "        \n",
    "        # 处理NA行\n",
    "        if not keep_na_row:\n",
    "            result = result[result[\"keep\"] == \"1\"].copy()\n",
    "        \n",
    "        # 处理第一行\n",
    "        if len(result) > 1 and result.iloc[0, 2:].isna().all():\n",
    "            if keep_first:\n",
    "                result.iloc[0, 1] = \"0\"\n",
    "            else:\n",
    "                result = result.iloc[1:].copy()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _resample_long(self, ds: pd.DataFrame, time_list: List[int], \n",
    "                    itemid_list: List[str], type_list: List[str], \n",
    "                    agg_funcs: List[Union[str, Callable]], \n",
    "                    itemid_col: str, value_col: str, time_col: str, \n",
    "                    end_col: str = None, time_window: int = 1,\n",
    "                    direction: str = \"both\", keep_na_row: bool = False, \n",
    "                    keep_first: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Resample long format data.\n",
    "        \n",
    "        Args:\n",
    "            ds: Input DataFrame\n",
    "            time_list: List of time points to sample at\n",
    "            itemid_list: List of item IDs\n",
    "            type_list: List of variable types\n",
    "            agg_funcs: List of aggregation functions\n",
    "            itemid_col: Column name for item IDs\n",
    "            value_col: Column name for values\n",
    "            time_col: Name of time column\n",
    "            end_col: Name of end time column (optional)\n",
    "            time_window: Size of time window\n",
    "            direction: Direction of time window ('both', 'left', or 'right')\n",
    "            keep_na_row: Whether to keep rows with all NA values\n",
    "            keep_first: Whether to keep first row if all NA\n",
    "            \n",
    "        Returns:\n",
    "            Resampled DataFrame\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # 对每个时间点进行处理\n",
    "        for cur_t in time_list:\n",
    "            # 根据是否有区间数据确定时间过滤条件\n",
    "            if end_col is None:\n",
    "                # 点数据的时间过滤\n",
    "                if direction == \"both\":\n",
    "                    time_mask = (ds[time_col] >= (cur_t - time_window/2)) & \\\n",
    "                            (ds[time_col] <= (cur_t + time_window/2))\n",
    "                elif direction == \"left\":\n",
    "                    time_mask = (ds[time_col] >= (cur_t - time_window)) & \\\n",
    "                            (ds[time_col] <= cur_t)\n",
    "                elif direction == \"right\":\n",
    "                    time_mask = (ds[time_col] >= cur_t) & \\\n",
    "                            (ds[time_col] <= (cur_t + time_window))\n",
    "            else:\n",
    "                # 区间数据的时间过滤\n",
    "                if direction == \"both\":\n",
    "                    time_mask = ((ds[end_col].isna() & \n",
    "                                (ds[time_col] >= (cur_t - time_window/2)) & \n",
    "                                (ds[time_col] <= (cur_t + time_window/2))) |\n",
    "                            (~ds[end_col].isna() & \n",
    "                                (ds[time_col] <= (cur_t + time_window/2)) & \n",
    "                                (ds[end_col] >= (cur_t - time_window/2))))\n",
    "                elif direction == \"left\":\n",
    "                    time_mask = ((ds[end_col].isna() & \n",
    "                                (ds[time_col] >= (cur_t - time_window)) & \n",
    "                                (ds[time_col] <= cur_t)) |\n",
    "                            (~ds[end_col].isna() & \n",
    "                                (ds[time_col] <= cur_t) & \n",
    "                                (ds[end_col] >= (cur_t - time_window))))\n",
    "                elif direction == \"right\":\n",
    "                    time_mask = ((ds[end_col].isna() & \n",
    "                                (ds[time_col] >= cur_t) & \n",
    "                                (ds[time_col] <= (cur_t + time_window))) |\n",
    "                            (~ds[end_col].isna() & \n",
    "                                (ds[time_col] <= (cur_t + time_window)) & \n",
    "                                (ds[end_col] >= cur_t)))\n",
    "            \n",
    "            ds_cur = ds[time_mask].copy()\n",
    "            \n",
    "            if len(ds_cur) == 0:\n",
    "                results.append([\"0\"] + [None] * len(itemid_list))\n",
    "                continue\n",
    "                \n",
    "            # 计算重叠部分（仅对区间数据）\n",
    "            if end_col is not None:\n",
    "                if direction == \"both\":\n",
    "                    overlap = np.minimum(ds_cur[end_col], cur_t + time_window/2) - \\\n",
    "                            np.maximum(ds_cur[time_col], cur_t - time_window/2)\n",
    "                elif direction == \"left\":\n",
    "                    overlap = np.minimum(ds_cur[end_col], cur_t) - \\\n",
    "                            np.maximum(ds_cur[time_col], cur_t - time_window)\n",
    "                elif direction == \"right\":\n",
    "                    overlap = np.minimum(ds_cur[end_col], cur_t + time_window) - \\\n",
    "                            np.maximum(ds_cur[time_col], cur_t)\n",
    "                \n",
    "                overlap = np.maximum(overlap, 0)\n",
    "                total = ds_cur[end_col] - ds_cur[time_col]\n",
    "                ds_cur['proportion'] = overlap / total\n",
    "            \n",
    "            # 对每个变量应用聚合函数\n",
    "            cur_x = []\n",
    "            for itemid, var_type, agg_f in zip(itemid_list, type_list, agg_funcs):\n",
    "                # 获取当前变量的数据\n",
    "                mask = ds_cur[itemid_col] == itemid\n",
    "                x = ds_cur.loc[mask, value_col]\n",
    "                \n",
    "                if len(x) == 0:\n",
    "                    cur_x.append(None)\n",
    "                    continue\n",
    "                \n",
    "                if var_type == \"num\":\n",
    "                    x = pd.to_numeric(x, errors='coerce')\n",
    "                    if end_col is not None and agg_f in ['mean_w', 'median_w']:\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x, overlap[mask])\n",
    "                    elif end_col is not None and agg_f == 'sum_w':\n",
    "                        x = x * ds_cur.loc[mask, 'proportion']\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                    else:\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                elif var_type in [\"cat\", \"ord\"]:\n",
    "                    x = x.astype(str)\n",
    "                    if end_col is not None and agg_f == 'mode_w':\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x, overlap[mask])\n",
    "                    else:\n",
    "                        agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                elif var_type == \"bin\":\n",
    "                    x = pd.to_numeric(x, errors='coerce')\n",
    "                    agg_value = self.AGG_FUNCS[agg_f](x)\n",
    "                \n",
    "                cur_x.append(agg_value)\n",
    "            \n",
    "            results.append([\"1\"] + cur_x)\n",
    "        \n",
    "        # 转换为DataFrame\n",
    "        result = pd.DataFrame(results, columns=[\"keep\"] + itemid_list)\n",
    "        result.insert(0, \"time\", time_list)\n",
    "        \n",
    "        # 处理NA行\n",
    "        if not keep_na_row:\n",
    "            result = result[result[\"keep\"] == \"1\"].copy()\n",
    "        \n",
    "        # 处理第一行\n",
    "        if len(result) > 1 and result.iloc[0, 2:].isna().all():\n",
    "            if keep_first:\n",
    "                result.iloc[0, 1] = \"0\"\n",
    "            else:\n",
    "                result = result.iloc[1:].copy()\n",
    "        \n",
    "        return result\n",
    "    ##############################\n",
    "    # Fill Missing Values\n",
    "    ##############################\n",
    "\n",
    "    def _fill_lin(self, x: pd.Series, time: pd.Index) -> pd.Series:\n",
    "        \"\"\"Fill missing values using linear interpolation.\n",
    "        \n",
    "        Args:\n",
    "            x: Series with missing values\n",
    "            time: Time index or series\n",
    "        \"\"\"\n",
    "        result = x.copy()\n",
    "        \n",
    "        # Get indices of NA and non-NA values\n",
    "        na_idx = x.isna()\n",
    "        non_na_idx = ~na_idx\n",
    "        \n",
    "        # If all values are NA or no values are NA, return original series\n",
    "        if na_idx.all() or not na_idx.any():\n",
    "            return result\n",
    "            \n",
    "        # Convert time to numeric series if it's not already\n",
    "        if isinstance(time, pd.Index):\n",
    "            time = pd.Series(time.values, index=time)\n",
    "        \n",
    "        # Iterate through NA indices\n",
    "        for idx in x[na_idx].index:\n",
    "            # Find nearest non-missing values on both sides\n",
    "            left_vals = x[non_na_idx & (time < time[idx])]\n",
    "            right_vals = x[non_na_idx & (time > time[idx])]\n",
    "            \n",
    "            if len(left_vals) > 0 and len(right_vals) > 0:\n",
    "                # Get nearest values\n",
    "                left_val = left_vals.iloc[-1]\n",
    "                right_val = right_vals.iloc[0]\n",
    "                left_time = time[left_vals.index[-1]]\n",
    "                right_time = time[right_vals.index[0]]\n",
    "                \n",
    "                # Linear interpolation\n",
    "                result[idx] = (\n",
    "                    left_val + \n",
    "                    (right_val - left_val) * \n",
    "                    (time[idx] - left_time) / \n",
    "                    (right_time - left_time)\n",
    "                )\n",
    "            elif len(left_vals) > 0:\n",
    "                # If only left values exist, use last left value\n",
    "                result[idx] = left_vals.iloc[-1]\n",
    "            elif len(right_vals) > 0:\n",
    "                # If only right values exist, use first right value\n",
    "                result[idx] = right_vals.iloc[0]\n",
    "                \n",
    "        return result\n",
    "\n",
    "    def _fill_column(self, series: pd.Series, value_type: str,\n",
    "                    fill1: str, fill2: str, time_col: pd.Series = None,\n",
    "                    stats: Dict = None) -> pd.Series:\n",
    "        \"\"\"Fill missing values based on value type and fill methods.\"\"\"\n",
    "        if stats is None or not isinstance(stats, dict):\n",
    "            raise ValueError(\"stats must be provided as a dictionary\")\n",
    "        \n",
    "        result = series.copy()\n",
    "        if not result.isna().any():\n",
    "            return result\n",
    "\n",
    "        # Get continuation value based on type\n",
    "        cont = stats.get(\"cont\")\n",
    "        if pd.isna(cont):\n",
    "            if value_type == \"num\":\n",
    "                cont = stats.get(\"mean\")\n",
    "            elif value_type in [\"cat\", \"ord\"]:  # 合并处理 cat 和 ord\n",
    "                cont = stats.get(\"mode\")\n",
    "            elif value_type == \"bin\":\n",
    "                cont = 0\n",
    "\n",
    "        # Fill first missing value\n",
    "        if pd.isna(result.iloc[0]):\n",
    "            if value_type == \"num\":\n",
    "                if fill1 == \"mean\":\n",
    "                    result.iloc[0] = stats.get(\"mean\")\n",
    "                elif fill1 == \"median\":\n",
    "                    result.iloc[0] = stats.get(\"mean\")  # 使用 mean 替代 median\n",
    "                elif fill1 == \"cont\":\n",
    "                    result.iloc[0] = cont\n",
    "                elif fill1 == \"mean_k\":\n",
    "                    result.iloc[0] = (cont if result.isna().all() \n",
    "                                    else result.mean(skipna=True))\n",
    "                elif fill1 == \"median_k\":\n",
    "                    result.iloc[0] = (cont if result.isna().all() \n",
    "                                    else result.mean(skipna=True))  # 使用 mean 替代 median\n",
    "            elif value_type in [\"cat\", \"ord\"]:  # 合并处理 cat 和 ord\n",
    "                if fill1 in [\"mode\", \"median\", \"mean\"]:  # 所有数值相关的填充方法都使用 mode\n",
    "                    result.iloc[0] = stats.get(\"mode\")\n",
    "                elif fill1 == \"cont\":\n",
    "                    result.iloc[0] = cont\n",
    "                elif fill1 in [\"mode_k\", \"mean_k\", \"median_k\"]:  # 所有 *_k 方法都使用 mode_k\n",
    "                    result.iloc[0] = (cont if result.isna().all() \n",
    "                                    else self._calculate_mode(result))\n",
    "            elif value_type == \"bin\":\n",
    "                if fill1 == \"cont\":\n",
    "                    result.iloc[0] = cont\n",
    "                \n",
    "            if fill1 == \"locb\":\n",
    "                first_valid = result.first_valid_index()\n",
    "                result.iloc[0] = (cont if first_valid is None \n",
    "                                else result.iloc[first_valid])\n",
    "            elif fill1 == \"zero\":\n",
    "                result.iloc[0] = 0\n",
    "\n",
    "        # Fill remaining missing values\n",
    "        if value_type == \"num\":\n",
    "            if fill2 == \"lin\" and time_col is not None:\n",
    "                result = self._fill_lin(result, time_col)\n",
    "            elif fill2 == \"mean\":\n",
    "                result.fillna(stats.get(\"mean\"), inplace=True)\n",
    "            elif fill2 == \"median\":\n",
    "                result.fillna(stats.get(\"mean\"), inplace=True)  # 使用 mean 替代 median\n",
    "            elif fill2 == \"mean_k\":\n",
    "                fill_value = cont if result.isna().all() else result.mean(skipna=True)\n",
    "                result.fillna(fill_value, inplace=True)\n",
    "            elif fill2 == \"median_k\":\n",
    "                fill_value = cont if result.isna().all() else result.mean(skipna=True)  # 使用 mean 替代 median\n",
    "                result.fillna(fill_value, inplace=True)\n",
    "        elif value_type in [\"cat\", \"ord\"]:  # 合并处理 cat 和 ord\n",
    "            if fill2 in [\"mode\", \"mean\", \"median\"]:  # 所有数值相关的填充方法都使用 mode\n",
    "                result.fillna(stats.get(\"mode\"), inplace=True)\n",
    "            elif fill2 in [\"mode_k\", \"mean_k\", \"median_k\"]:  # 所有 *_k 方法都使用 mode_k\n",
    "                fill_value = cont if result.isna().all() else self._calculate_mode(result)\n",
    "                result.fillna(fill_value, inplace=True)\n",
    "        \n",
    "        # Common fill methods for all types\n",
    "        if fill2 == \"zero\":\n",
    "            result.fillna(0, inplace=True)\n",
    "        elif fill2 == \"cont\":\n",
    "            result.fillna(cont, inplace=True)\n",
    "        elif fill2 == \"locf\":\n",
    "            result.fillna(method='ffill', inplace=True)\n",
    "        elif fill2 == \"locb\":\n",
    "            result.fillna(method='bfill', inplace=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def fill_missing(self, resampled: pd.DataFrame, col_list: List[str], time_col: str,\n",
    "                    type_list: List[str], fill1_list: List[str],\n",
    "                    fill2_list: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Fill missing values for resampled data.\n",
    "        \n",
    "        Args:\n",
    "            resampled: Resampled DataFrame (output from resample method)\n",
    "            col_list: List of column names to process\n",
    "            time_col: Name of time column\n",
    "            type_list: List of variable types\n",
    "            fill1_list: List of methods to fill first missing value\n",
    "            fill2_list: List of methods to fill remaining missing values\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with filled missing values\n",
    "        \"\"\"\n",
    "        result = resampled.copy()\n",
    "        \n",
    "        # Fill missing values for each column\n",
    "        for col, vtype, fill1, fill2 in zip(col_list, type_list, fill1_list, fill2_list):\n",
    "            result[col] = self._fill_column(\n",
    "                series=result[col],\n",
    "                value_type=vtype,\n",
    "                fill1=fill1,\n",
    "                fill2=fill2,\n",
    "                time_col=result[time_col],\n",
    "                stats=self.stats.get(col, {})\n",
    "            )\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def fill_last_values(self, ds: pd.DataFrame, mask: pd.DataFrame, \n",
    "                        itemid_col: str = 'itemid') -> pd.DataFrame:\n",
    "        \"\"\"Fill missing values with last non-missing value for each variable.\n",
    "        \n",
    "        Args:\n",
    "            ds: Resampled DataFrame\n",
    "            mask: Binary mask indicating presence (1) or absence (0) of values\n",
    "            itemid_col: Name of the itemid column in self.var_dict (default: 'itemid')\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with missing values filled using last non-missing values\n",
    "        \"\"\"\n",
    "        result = ds.copy()\n",
    "        itemid_list = self.var_dict[itemid_col].tolist()\n",
    "        \n",
    "        # 处理每个变量\n",
    "        for i, col in enumerate(itemid_list):\n",
    "            # 找到mask中值为1的位置\n",
    "            ind = mask[col] == 1\n",
    "            if not ind.any():\n",
    "                continue\n",
    "                \n",
    "            # 找到最后一个非缺失值的位置\n",
    "            last_present = ind.values.nonzero()[0][-1]\n",
    "            first_ind = last_present + 1\n",
    "            \n",
    "            # 如果first_ind已经是最后一个观测，则跳过\n",
    "            if first_ind >= len(result):\n",
    "                continue\n",
    "                \n",
    "            # 使用self.var_dict获取last_value\n",
    "            last_value = self.var_dict.loc[self.var_dict[itemid_col] == col, 'last_value'].iloc[0]\n",
    "            if pd.notna(last_value):\n",
    "                result.iloc[first_ind:, result.columns.get_loc(col)] = last_value\n",
    "        \n",
    "        return result\n",
    "\n",
    "    ##############################\n",
    "    # Mask and Delta Time\n",
    "    ##############################\n",
    "    def shape_as_onehot(self, ds: pd.DataFrame, col_list: List[str], \n",
    "                        time_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Shape matrix to match one-hot encoding structure without actual encoding.\"\"\"\n",
    "        # 生成结果列名\n",
    "        shaped_cols = []\n",
    "        for col in col_list:\n",
    "            var_type = self.var_dict.loc[self.var_dict['itemid'] == col, 'value_type'].iloc[0]\n",
    "            if var_type in ['num', 'bin']:  # 移除 'ord'\n",
    "                shaped_cols.append(col)\n",
    "            else:  # categorical 和 ordinal\n",
    "                n_categories = len(self.stats[col]['unique_values'])\n",
    "                shaped_cols.extend([f\"{col}___{i+1}\" for i in range(n_categories)])\n",
    "        \n",
    "        # 创建结果 DataFrame，从时间列开始\n",
    "        result = [ds[time_col]]\n",
    "        \n",
    "        # 处理每一列\n",
    "        for col in col_list:\n",
    "            var_type = self.var_dict.loc[self.var_dict['itemid'] == col, 'value_type'].iloc[0]\n",
    "            if var_type in ['num', 'bin']:  # 移除 'ord'\n",
    "                result.append(ds[col])\n",
    "            else:  # categorical 和 ordinal\n",
    "                n_categories = len(self.stats[col]['unique_values'])\n",
    "                repeated_cols = [ds[col].copy() for _ in range(n_categories)]\n",
    "                result.extend(repeated_cols)\n",
    "        \n",
    "        # 合并所有列并设置列名\n",
    "        result = pd.concat(result, axis=1)\n",
    "        result.columns = [time_col] + shaped_cols\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def get_mask(self, ds: pd.DataFrame, itemid_list: List[str], time_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Generate missing value mask for resampled variables.\n",
    "        \n",
    "        Args:\n",
    "            ds: Resampled DataFrame (output from resample method)\n",
    "            itemid_list: List of item IDs\n",
    "            time_col: Name of time column\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with binary mask indicating presence (1) or absence (0) of values\n",
    "        \"\"\"\n",
    "        # Create mask for resampled columns\n",
    "        mask = ds[itemid_list].notna().astype(int)\n",
    "        \n",
    "        # Add time column\n",
    "        result = pd.concat([ds[time_col], mask], axis=1)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def get_delta_time(self, ds: pd.DataFrame, itemid_list: List[str], \n",
    "                    time_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Calculate time differences for resampled variables.\n",
    "        \n",
    "        Args:\n",
    "            ds: Resampled DataFrame (output from resample method)\n",
    "            itemid_list: List of item IDs\n",
    "            time_col: Name of time column\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with time differences since last non-missing value\n",
    "        \"\"\"\n",
    "        # 创建一个新的DataFrame来存储时间差\n",
    "        delta = pd.DataFrame(index=ds.index)\n",
    "        time_values = ds[time_col].values\n",
    "        \n",
    "        # 为每个变量计算时间差\n",
    "        for col in itemid_list:\n",
    "            mask = ds[col].notna().astype(int).values\n",
    "            delta[col] = np.zeros(len(mask))\n",
    "            \n",
    "            for t in range(1, len(mask)):\n",
    "                if mask[t] == 1:  # 当前时间点有值\n",
    "                    if mask[t-1] == 0:  # 前一个时间点无值\n",
    "                        # 找到前一个有值的位置\n",
    "                        last_valid = t - 1\n",
    "                        while last_valid >= 0 and mask[last_valid] == 0:\n",
    "                            last_valid -= 1\n",
    "                        \n",
    "                        if last_valid >= 0:\n",
    "                            delta[col].iloc[t] = time_values[t] - time_values[last_valid]\n",
    "                        else:\n",
    "                            delta[col].iloc[t] = 0  # 如果之前没有值，设为0\n",
    "                    else:  # 前一个时间点有值\n",
    "                        delta[col].iloc[t] = time_values[t] - time_values[t-1]\n",
    "                else:  # 当前时间点无值\n",
    "                    delta[col].iloc[t] = 0\n",
    "        \n",
    "        # 添加时间列\n",
    "        result = pd.concat([ds[time_col], delta], axis=1)\n",
    "        return result\n",
    "\n",
    "    def process_temporal_features(self, ds: pd.DataFrame, col_list: List[str], \n",
    "                                time_col: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Process temporal features including mask and delta time.\n",
    "        \n",
    "        Args:\n",
    "            ds: Input DataFrame\n",
    "            col_list: List of column names\n",
    "            time_col: Name of time column\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing processed features:\n",
    "            - 'mask': Shaped mask matrix\n",
    "            - 'delta': Shaped delta time matrix\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        \n",
    "        # 生成 mask 矩阵\n",
    "        mask = self.get_mask(ds, col_list, time_col)\n",
    "        # 转换 mask 矩阵结构\n",
    "        shaped_mask = self.shape_as_onehot(mask, col_list, time_col)\n",
    "        result['mask'] = shaped_mask\n",
    "        \n",
    "        # 生成 delta time 矩阵\n",
    "        delta = self.get_delta_time(ds, col_list, time_col)\n",
    "        # 转换 delta time 矩阵结构\n",
    "        shaped_delta = self.shape_as_onehot(delta, col_list, time_col)\n",
    "        result['delta'] = shaped_delta\n",
    "        \n",
    "        return result\n",
    "\n",
    "    ##############################\n",
    "    # One-hot Encoding\n",
    "    ##############################\n",
    "    def to_onehot(self, ds: pd.DataFrame, col_list: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Convert categorical columns to one-hot encoding.\"\"\"\n",
    "        result_cols = []\n",
    "        \n",
    "        for col in col_list:\n",
    "            # 从 self.var_dict 获取变量类型\n",
    "            dtype = self.var_dict.loc[self.var_dict['itemid'] == col, 'value_type'].iloc[0]\n",
    "            \n",
    "            if dtype in ['num', 'bin']:  # 移除 'ord'\n",
    "                result_cols.append(ds[col])\n",
    "            else:  # categorical 和 ordinal\n",
    "                # 从 self.stats 获取唯一值\n",
    "                unique_values = self.stats[col]['unique_values']\n",
    "                \n",
    "                # 创建 one-hot 列\n",
    "                for i, val in enumerate(unique_values, 1):\n",
    "                    col_name = f\"{col}___{i}\"\n",
    "                    result_cols.append(\n",
    "                        pd.Series(\n",
    "                            (ds[col] == val).astype(int),\n",
    "                            name=col_name\n",
    "                        )\n",
    "                    )\n",
    "        \n",
    "        # 合并所有列\n",
    "        result = pd.concat([ds.iloc[:, 0]] + result_cols, axis=1)  # 保留时间列\n",
    "        return result\n",
    "\n",
    "    def rev_onehot(self, ds: pd.DataFrame, col_list: List[str], time_col: str) -> pd.DataFrame:\n",
    "        \"\"\"Reverse one-hot encoding back to original data format.\"\"\"\n",
    "        result_cols = []\n",
    "        \n",
    "        # 保留时间列\n",
    "        result_cols.append(ds[time_col])\n",
    "        \n",
    "        current_pos = 0\n",
    "        # 处理每个原始列\n",
    "        for col in col_list:\n",
    "            # 获取变量类型\n",
    "            var_type = self.var_dict.loc[self.var_dict['itemid'] == col, 'value_type'].iloc[0]\n",
    "            \n",
    "            if var_type in ['num', 'bin']:  # 移除 'ord'\n",
    "                # 数值型列直接保留\n",
    "                result_cols.append(ds[col])\n",
    "                current_pos += 1\n",
    "            else:  # categorical 和 ordinal\n",
    "                # 获取该分类变量的所有可能值\n",
    "                unique_values = self.stats[col]['unique_values']\n",
    "                n_categories = len(unique_values)\n",
    "                \n",
    "                # 获取one-hot列\n",
    "                onehot_cols = [f\"{col}___{i+1}\" for i in range(n_categories)]\n",
    "                onehot_data = ds[onehot_cols]\n",
    "                \n",
    "                # 转换回原始分类\n",
    "                def get_category(row):\n",
    "                    # 找到值为1的位置\n",
    "                    ind = row.values.nonzero()[0]\n",
    "                    if len(ind) == 0:\n",
    "                        return pd.NA\n",
    "                    return unique_values[ind[0]]\n",
    "                \n",
    "                reversed_col = onehot_data.apply(get_category, axis=1)\n",
    "                reversed_col.name = col\n",
    "                result_cols.append(reversed_col)\n",
    "                current_pos += n_categories\n",
    "        \n",
    "        # 合并所有列\n",
    "        result = pd.concat(result_cols, axis=1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = pd.read_excel(\"var_dict.xlsx\", sheet_name=0)\n",
    "# 根据 table_type 读取数据\n",
    "table_type = \"long\"  # 或 \"long\"\n",
    "dtype_dict = get_dtype_dict(var_dict, table_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_excel(\"data.xlsx\", sheet_name=0, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_map = pd.read_excel(\"var_dict.xlsx\", sheet_name=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建EMR_LIP实例\n",
    "emr = EMR_LIP(var_dict, table_type=\"long\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重命名\n",
    "ds = emr.rename_table(ds, ds_map['old_name'].tolist(), \n",
    "                ds_map['new_name'].tolist(), \n",
    "                name_col=\"item_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>time</th>\n",
       "      <th>time2</th>\n",
       "      <th>item_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sid  time  time2 item_id value\n",
       "0     1     1    NaN       A     2\n",
       "1     1     1    NaN       B     1\n",
       "2     1     1    NaN       C     b\n",
       "3     1     1    NaN       D     0\n",
       "4     1     1    NaN       A     8\n",
       "..  ...   ...    ...     ...   ...\n",
       "57    1    12    NaN       D     1\n",
       "58    1    12    NaN       A     5\n",
       "59    1    12    NaN       B     3\n",
       "60    1    12    NaN       C     c\n",
       "61    1    12    NaN       D     0\n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移除极值\n",
    "ds = emr.remove_extreme_values(\n",
    "    ds, \n",
    "    var_dict['itemid'].tolist(),\n",
    "    var_dict['value_type'].tolist(),\n",
    "    itemid_col=\"item_id\",\n",
    "    value_col=\"value\",\n",
    "    sep=\"|\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>time</th>\n",
       "      <th>time2</th>\n",
       "      <th>item_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sid  time  time2 item_id value\n",
       "0     1     1    NaN       A     2\n",
       "1     1     1    NaN       B     1\n",
       "2     1     1    NaN       C     b\n",
       "3     1     1    NaN       D     0\n",
       "4     1     1    NaN       A     8\n",
       "..  ...   ...    ...     ...   ...\n",
       "57    1    12    NaN       D     1\n",
       "58    1    12    NaN       A     5\n",
       "59    1    12    NaN       B     3\n",
       "60    1    12    NaN       C     c\n",
       "61    1    12    NaN       D     0\n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算统计量 - 修正这里的参数名\n",
    "emr.calculate_stats(\n",
    "    ds,\n",
    "    var_dict['itemid'].tolist(),\n",
    "    var_dict['value_type'].tolist(),\n",
    "    itemid_col=\"item_id\",\n",
    "    value_col=\"value\",\n",
    "    cont_list=var_dict['cont'].tolist()  # 改为 cont_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'type': 'num', 'mean': 3.2857142857142856, 'cont': 6},\n",
       " 'B': {'type': 'ord',\n",
       "  'mode': '2',\n",
       "  'unique_values': ['1', '2', '3', '4'],\n",
       "  'cont': 3},\n",
       " 'C': {'type': 'cat',\n",
       "  'mode': 'a',\n",
       "  'unique_values': ['a', 'b', 'c', 'd'],\n",
       "  'cont': 'a'},\n",
       " 'D': {'type': 'bin', 'mean': 0.5, 'cont': 1},\n",
       " 'E': {'type': 'num', 'mean': 2.0, 'cont': 2}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emr.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理单个病人的数据\n",
    "ds_k = ds[ds['sid'] == 1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_k1 = emr.resample(\n",
    "    ds_k,\n",
    "    time_list=list(range(1,5)),\n",
    "    itemid_list=var_dict['itemid'].tolist(),\n",
    "    type_list=var_dict['value_type'].tolist(),\n",
    "    agg_funcs=var_dict['agg_fun'].tolist(),\n",
    "    time_col=\"time\",\n",
    "    value_col=\"value\",\n",
    "    itemid_col=\"item_id\",  # 指定 itemid_col\n",
    "    time_window=1,\n",
    "    direction=\"both\",\n",
    "    start_col=\"time\",\n",
    "    end_col=\"time2\",\n",
    "    keep_na_row = True,\n",
    "    keep_first = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>keep</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time keep    A  B     C    D         E\n",
       "0     1    1  5.0  1     b  0.0  0.166667\n",
       "1     2    1  NaN  2  None  NaN  0.666667\n",
       "2     3    1  3.0  3     c  1.0  1.750000\n",
       "3     4    1  3.0  2     a  1.0  2.833333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = emr.get_mask(\n",
    "    ds_k1,\n",
    "    var_dict['itemid'].tolist(),\n",
    "    time_col=\"time\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充缺失值\n",
    "ds_k1 = emr.fill_missing(\n",
    "    ds_k1,\n",
    "    col_list=var_dict['itemid'].tolist(),\n",
    "    time_col=\"time\",\n",
    "    type_list=var_dict['value_type'].tolist(),\n",
    "    fill1_list=var_dict['fill1'].tolist(),\n",
    "    fill2_list=var_dict['fill2'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_k1 = emr.fill_last_values(\n",
    "    ds=ds_k1,\n",
    "    mask=mask,\n",
    "    itemid_col=\"itemid\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将填充后的数据进行one-hot编码\n",
    "ds_k1 = emr.to_onehot(\n",
    "    ds_k1,  # 填充后的数据框\n",
    "    var_dict['itemid'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>A</th>\n",
       "      <th>B___1</th>\n",
       "      <th>B___2</th>\n",
       "      <th>B___3</th>\n",
       "      <th>B___4</th>\n",
       "      <th>C___1</th>\n",
       "      <th>C___2</th>\n",
       "      <th>C___3</th>\n",
       "      <th>C___4</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time    A  B___1  B___2  B___3  B___4  C___1  C___2  C___3  C___4    D  \\\n",
       "0     1  5.0      1      0      0      0      0      1      0      0  0.0   \n",
       "1     2  4.0      0      1      0      0      0      1      0      0  0.0   \n",
       "2     3  3.0      0      0      1      0      0      0      1      0  1.0   \n",
       "3     4  3.0      0      1      0      0      1      0      0      0  1.0   \n",
       "\n",
       "          E  \n",
       "0  0.166667  \n",
       "1  0.666667  \n",
       "2  1.750000  \n",
       "3  2.833333  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
